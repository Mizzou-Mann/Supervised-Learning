% assignment_1.tex
% CS 8725 - Supervised Learning (Fall 2015)
%     University of Missouri-Columbia
%             Chanmann Lim
%            September 2015

\documentclass[a4paper]{article}

\usepackage[margin=1 in]{geometry}
\usepackage{amsmath}

\everymath{\displaystyle}

\begin{document}
\title{CS 8725: Report for assignment 1}
\author{Chanmann Lim}
\date{September 1, 2015}
\maketitle

Let $\hat{\theta}$ be the estimation of the probability of the coin show up head $P(Head)$, and $\theta^*$ be the true value of $P(Head)$. If there is a constraint on the error bound $\epsilon$ to guarantee that the accuracy of the estimation is larger than $1 - \delta$ where $\delta$ denotes the failure probability and from the theory of probability we understand that the accuracy is just the complement the probability of error. Then we obtain

\begin{align}
P(|\hat{\theta} - \theta^*| < \epsilon) &\ge 1 - \delta \\
1 - P(|\hat{\theta} - \theta^*| \ge \epsilon) &\ge 1 - \delta \\
P(|\hat{\theta} - \theta^*| \ge \epsilon) &\le \delta
\end{align}

According to Hoeffding's inequality we have

\begin{equation}
P(|\hat{\theta} - \theta^*| \ge \epsilon) \le 2e^{-2n\epsilon^2}
\end{equation}

And in order to guarantee that $P(|\hat{\theta} - \theta^*| \ge \epsilon)$ is always less than or equal to $\delta$, the upper bound of the probability of error $2e^{-2n\epsilon^2}$ must be less than or equal to $\delta$.

\begin{align*}
2e^{-2n\epsilon^2} &\le \delta \\
ln(2) - 2n\epsilon^2 &\le ln(\delta) \\
ln(2) - ln(\delta) &\le 2n\epsilon^2 \\
ln(2/\delta) &\le 2n\epsilon^2 \\
\frac{ln(2/\delta)}{2\epsilon^2} &\le n
\end{align*}

Therefore,

\begin{displaymath}
n \ge \frac{ln(2/\delta)}{2\epsilon^2}
\end{displaymath}
\end{document}